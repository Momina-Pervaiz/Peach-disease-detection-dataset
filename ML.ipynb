{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1W_ldtpG2izD",
        "outputId": "3bdd66bf-ca39-45bf-c3d9-4d9e53f9fe52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "1fuE6NFe2zQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_from_folder(folder, image_size=(128, 128)):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for label in os.listdir(folder):\n",
        "        label_folder = os.path.join(folder, label)\n",
        "        if os.path.isdir(label_folder):\n",
        "            for filename in os.listdir(label_folder):\n",
        "                img_path = os.path.join(label_folder, filename)\n",
        "                try:\n",
        "                    img = Image.open(img_path).convert('RGB')\n",
        "                    img = img.resize(image_size)\n",
        "                    img_array = np.array(img).flatten()  # Flatten the image\n",
        "                    images.append(img_array)\n",
        "                    labels.append(label)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error loading image {img_path}: {e}\")\n",
        "    return np.array(images), np.array(labels)\n"
      ],
      "metadata": {
        "id": "T9JVPMug2-oZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_classes(folder_path):\n",
        "    return len([name for name in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, name))])\n"
      ],
      "metadata": {
        "id": "7WWehKs23E7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    return accuracy, precision, recall, f1\n",
        "\n"
      ],
      "metadata": {
        "id": "Oxq9Siqb3KgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_folder_path = '/content/drive/My Drive/dataset/train'\n",
        "test_folder_path = '/content/drive/My Drive/dataset/test'\n",
        "X_train, y_train = load_images_from_folder(train_folder_path, image_size=(128, 128))\n",
        "X_test, y_test = load_images_from_folder(test_folder_path, image_size=(128, 128))\n"
      ],
      "metadata": {
        "id": "p18v7WW03rtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install scikit-learn\n",
        "from sklearn.preprocessing import LabelEncoder  # Import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Tlb4b1635XeG",
        "outputId": "27a1176f-42eb-4402-edee-33f4a8eb3813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the data (recommended for certain algorithms)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "_cNRl1PZ5cGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define models\n",
        "models = {\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"KNN\": KNeighborsClassifier(n_neighbors=1),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=500),  # Increased max_iter\n",
        "    \"SVM\": SVC(),\n",
        "    \"ANN\": MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=100)  # Adjust ANN parameters\n",
        "}\n"
      ],
      "metadata": {
        "id": "zwUqZaOg5hVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate each model\n",
        "results = []\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train_scaled, y_train_encoded)  # Use scaled data\n",
        "    y_pred = model.predict(X_test_scaled)  # Ensure predictions are class labels\n",
        "    accuracy = accuracy_score(y_test_encoded, y_pred)\n",
        "    precision = precision_score(y_test_encoded, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test_encoded, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test_encoded, y_pred, average='weighted')\n",
        "    results.append([model_name, accuracy, precision, recall, f1])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1wptHqVe5oIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the metrics to percentages\n",
        "results_percentage = []\n",
        "for result in results:\n",
        "    algorithm = result[0]\n",
        "    accuracy = result[1] * 100\n",
        "    precision = result[2] * 100\n",
        "    recall = result[3] * 100\n",
        "    f1_score = result[4] * 100\n",
        "    results_percentage.append([algorithm, accuracy, precision, recall, f1_score])\n",
        "\n"
      ],
      "metadata": {
        "id": "4gxf1Usm6eSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display results in a table format\n",
        "import pandas as pd\n",
        "results_df = pd.DataFrame(results_percentage, columns=[\"Algorithm\", \"Accuracy (%)\", \"Precision (%)\", \"Recall (%)\", \"F1 Score (%)\"])\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMIQU0A66jca",
        "outputId": "85199540-85c5-4733-c363-2b0d56d93dfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Algorithm  Accuracy (%)  Precision (%)  Recall (%)  F1 Score (%)\n",
            "0        Decision Tree     43.902439      40.548416   43.902439     40.219504\n",
            "1                  KNN     54.878049      48.177740   54.878049     49.474619\n",
            "2  Logistic Regression     47.560976      46.510400   47.560976     45.816462\n",
            "3                  SVM     47.560976      42.978616   47.560976     44.277503\n",
            "4                  ANN     51.219512      47.856615   51.219512     47.882289\n"
          ]
        }
      ]
    }
  ]
}